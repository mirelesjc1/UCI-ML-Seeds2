{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2e110834e11fcf5500f4dd9e5f72b5b8",
     "grade": false,
     "grade_id": "cell-80b77fe0d5d362ae",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Explain the bias-variance tradeoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a3ae4a44207d40f055e076aabbb09b45",
     "grade": true,
     "grade_id": "cell-e573d055cfb4a916",
     "locked": false,
     "points": 4,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "#Read ISLR p33-37 (extra credit)\n",
    "A: Bias is the error introduced by fitting a complex data set using a simple method such as linear regression.  Variance is the amount f^ would change if we estimated it using a different training data set.  We want both values to be low, however both values can be influenced by the method selected and sometimes in opposite directions.  Knowing f in advance makes the method selection easier, however the goal is to solve the problem not knowing f.  We have to keep an open mind to determining f^ and use simple and complex methods to identify the best model solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "83886665b6d5458966acb332c5e17c68",
     "grade": false,
     "grade_id": "cell-c40be3d158eb9ad1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Discuss the pros and cons of using the BIC to select a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "25405a06bb3615c01ebf2da1294c49a8",
     "grade": true,
     "grade_id": "cell-5df930a8f675836a",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "A: Pros of BIC to select a model is it provides a simple comparison value to evaluate your models, the smaller the value the better including negative values.  The BIC function is also readily available to calculate the value of your models.\n",
    "The cons of BIC is that it does not give you a good understanding on the underlying data and may provide numerous possible model options.  It should mainly be used to eliminate bad models so you can focus your attention on the good model options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection on a Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try this from Brian\n",
    "wheat.seeds.data = read.csv('~/uclax-data-science/UCI-ML-Seeds/data/seeds_dataset.csv',\n",
    "        header=FALSE, sep=\"\")\n",
    "\n",
    "colnames(wheat.seeds.data) = c(\"area\", \"perimeter\", \"compactness\", \"kernel_length\", \"kernel_width\",\n",
    "                             \"asymmetry_coeff\", \"kernel_groove_length\", \"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get and load the data\n",
    "SEEDS_DATA_URL = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt'\n",
    "#seeds_df.data = read.csv(SEEDS_DATA_URL, sep=\"\\s+\", header=None)\n",
    "seeds_df.data = read.csv(SEEDS_DATA_URL, sep=\"\\s+\", header=None)\n",
    "#seeds_df.columns = [\"Area\",\"Perimeter\",\"Compactness\",\"KernelLength\",\"KernelWidth\",\"AsymmetryCoefficient\",\"KernelGrooveLength\",\"VarietyType\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_df.data = read.csv(\"data/Seeds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.data = read.csv(\"data/iris.csv\", row.names='X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.glm = glm(\"label ~ 1 + sepal_length + sepal_width + petal_length + petal_width\", data = iris.data)\n",
    "summary(iris.glm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pr(>|t|) value > .05 is significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Log-Likelihood\n",
    "\n",
    "Without going too far into the math, we can think of the log-likelihood as a **likelihood function** telling us how likely a model is given the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value is not human interpretable but is useful as a comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logLik(iris.glm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"All models are wrong, but some are useful.\" - George Box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might be concerned with one additional property - the **complexity** of the model. \n",
    "\n",
    "##### William of Occam\n",
    "\n",
    "[**Occam's razor**](https://en.wikipedia.org/wiki/Occam's_razor) is the problem-solving principle that, when presented with competing hypothetical answers to a problem, one should select the one that makes the fewest assumptions.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/a/ab/William_of_Ockham_-_Logica_1341.jpg\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can represent this idea of complexity in terms of both the number of features we use and the amount of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Information Criterion\n",
    "\n",
    "https://en.wikipedia.org/wiki/Bayesian_information_criterion\n",
    "\n",
    "The BIC is formally defined as\n",
    "\n",
    "$$ \\mathrm{BIC} = {\\ln(n)k - 2\\ln({\\widehat L})}. $$\n",
    "\n",
    "where\n",
    "\n",
    "- $\\widehat L$ = the maximized value of the likelihood function of the model $M$\n",
    "- $x$ = the observed data\n",
    "- $n$ = the number of data points in $x$, the number of observations, or equivalently, the sample size;\n",
    "- $k$ = the number of parameters estimated by the model. For example, in multiple linear regression, the estimated parameters are the intercept, the $q$ slope parameters, and the constant variance of the errors; thus, $k = q + 2$.\n",
    "\n",
    "\n",
    "It might help us to think of it as \n",
    "\n",
    "$$ \\mathrm{BIC} = \\text{complexity}-\\text{likelihood}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIC(iris.glm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = length(iris.glm$fitted.values)\n",
    "p = length(coefficients(iris.glm))\n",
    "\n",
    "likelihood = 2 * logLik(iris.glm)\n",
    "complexity = log(n)*(p+1)\n",
    "\n",
    "bic = complexity - likelihood\n",
    "bic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIC_of_model = function (model) {\n",
    "    n = length(model$fitted.values)\n",
    "    p = length(coefficients(model))\n",
    "\n",
    "    likelihood = 2 * logLik(model)\n",
    "    complexity = log(n)*(p+1)\n",
    "\n",
    "    bic = complexity - likelihood\n",
    "    return(bic)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIC_of_model(iris.glm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "Here, we choose the optimal model by removing features one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model backward selection for GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1  = \"label ~ 1 + sepal_length + sepal_width + petal_length + petal_width\"\n",
    "model_2a = \"label ~ 1 + sepal_length + sepal_width + petal_length\"\n",
    "model_2b = \"label ~ 1 + sepal_length + sepal_width                + petal_width\"\n",
    "model_2c = \"label ~ 1 + sepal_length               + petal_length + petal_width\"\n",
    "model_2d = \"label ~ 1                + sepal_width + petal_length + petal_width\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.glm.1 = glm(model_1, data=iris.data)\n",
    "iris.glm.2a = glm(model_2a, data=iris.data)\n",
    "iris.glm.2b = glm(model_2b, data=iris.data)\n",
    "iris.glm.2c = glm(model_2c, data=iris.data)\n",
    "iris.glm.2d = glm(model_2d, data=iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iris.glm.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c('model_1', BIC_of_model(iris.glm.1)))\n",
    "print(c('model_2a', BIC_of_model(iris.glm.2a )))\n",
    "print(c('model_2b', BIC_of_model(iris.glm.2b )))\n",
    "print(c('model_2c', BIC_of_model(iris.glm.2c )))\n",
    "print(c('model_2d', BIC_of_model(iris.glm.2d )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c('model_1', BIC(iris.glm.1)))\n",
    "print(c('model_2a', BIC(iris.glm.2a )))\n",
    "print(c('model_2b', BIC(iris.glm.2b )))\n",
    "print(c('model_2c', BIC(iris.glm.2c )))\n",
    "print(c('model_2d', BIC(iris.glm.2d )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1  = \"label ~ 1 + sepal_length + sepal_width + petal_length + petal_width\"\n",
    "model_2c = \"label ~ 1 + sepal_length               + petal_length + petal_width\"\n",
    "model_3a = \"label ~ 1 + sepal_length               + petal_length \"\n",
    "model_3b = \"label ~ 1 + sepal_length                              + petal_width\"\n",
    "model_3c = \"label ~ 1                              + petal_length + petal_width\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.glm.3a = glm(model_3a, data=iris.data)\n",
    "iris.glm.3b = glm(model_3b, data=iris.data)\n",
    "iris.glm.3c = glm(model_3c, data=iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c('model_1', BIC(iris.glm.1)))\n",
    "print(c('model_2c', BIC(iris.glm.2c )))\n",
    "print(c('model_3a', BIC(iris.glm.3a )))\n",
    "print(c('model_3b', BIC(iris.glm.3b )))\n",
    "print(c('model_3c', BIC(iris.glm.3c )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
